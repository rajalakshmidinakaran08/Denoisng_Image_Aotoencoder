{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urh9Dmk7TiMb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPool2D, UpSampling2D,Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "# to get the shape of the data\n",
        "print(\"x_train shape:\",x_train.shape)\n",
        "print(\"x_test shape\", x_test.shape)"
      ],
      "metadata": {
        "id": "pwO5ZfA-Tkfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.title(str(y_train[i]),fontsize = 16, color = 'black', pad = 2)\n",
        "  plt.imshow(x_train[i], cmap = plt.cm.binary )\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OeRCresvUUcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = x_test[:9000]\n",
        "test_images = x_test[9000:]"
      ],
      "metadata": {
        "id": "yblsIlCCUXD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = val_images.astype('float32') / 255.0\n",
        "val_images = np.reshape(val_images,(val_images.shape[0],28,28,1))\n",
        "\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "test_images = np.reshape(test_images,(test_images.shape[0],28,28,1))\n",
        "\n",
        "train_images = x_train.astype(\"float32\") / 255.0\n",
        "train_images = np.reshape(train_images, (train_images.shape[0],28,28,1))"
      ],
      "metadata": {
        "id": "WrbTDy5wUaF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factor = 0.39\n",
        "train_noisy_images = train_images + factor * np.random.normal(loc = 0.0,scale = 1.0,size = train_images.shape)\n",
        "val_noisy_images = val_images + factor * np.random.normal(loc = 0.0,scale = 1.0,size = val_images.shape)\n",
        "test_noisy_images = test_images + factor * np.random.normal(loc = 0.0,scale = 1.0,size = test_images.shape)\n",
        "\n",
        "# here maximum pixel value for our images may exceed 1 so we have to clip the images\n",
        "train_noisy_images = np.clip(train_noisy_images,0.,1.)\n",
        "val_noisy_images = np.clip(val_noisy_images,0.,1.)\n",
        "test_noisy_images = np.clip(test_noisy_images,0.,1.)"
      ],
      "metadata": {
        "id": "VUgNrbOvUaJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "\n",
        "for i in range(25):\n",
        "      plt.subplot(5,5,i+1)\n",
        "      plt.title(str(y_train[i]),fontsize = 16, color = 'black', pad = 2)\n",
        "      plt.imshow(train_noisy_images[i].reshape(1,28,28)[0], cmap = plt.cm.binary )\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mCfOCmbuUaMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# encoder network\n",
        "model.add(Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu', padding = 'same', input_shape = (28,28,1)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Conv2D(filters = 256, kernel_size = (2,2),strides = (2,2), activation = 'relu', padding = 'same'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Conv2D(filters = 256, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Conv2D(filters = 512, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Conv2D(filters = 512, kernel_size = (2,2),strides = (2,2), activation = 'relu', padding = 'same'))\n",
        "\n",
        "\n",
        "\n",
        "# decoder network\n",
        "model.add(Conv2D(filters = 512, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2DTranspose(filters = 512, kernel_size = (2,2), strides = (2,2),activation = 'relu', padding = 'same'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Conv2D(filters = 256, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Conv2D(filters = 256, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (2,2),strides = (2,2), activation = 'relu', padding = 'same'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters = 1, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n",
        "\n",
        "\n",
        "# to get the summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "UQMNnvqcUaPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPTIMIZER =  tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "LOSS = 'mean_squared_error'\n",
        "model.compile(optimizer =OPTIMIZER, loss = LOSS, metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Hp78nqClUmk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "BATCH_SIZE = 256\n",
        "VALIDATION = (val_noisy_images, val_images)\n",
        "history = model.fit(train_noisy_images, train_images,batch_size = BATCH_SIZE,epochs = EPOCHS, validation_data = VALIDATION)"
      ],
      "metadata": {
        "id": "xBAijpA9Urrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(2,1,1)\n",
        "plt.plot( history.history['loss'], label = 'loss')\n",
        "plt.plot( history.history['val_loss'], label = 'val_loss')\n",
        "plt.legend(loc = 'best')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot( history.history['accuracy'], label = 'accuracy')\n",
        "plt.plot( history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A9Oj5OC1Ut5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (18,18))\n",
        "for i in range(10,19):\n",
        "    plt.subplot(9,9,i)\n",
        "    if(i == 14):\n",
        "        plt.title('Real Images', fontsize = 25, color = 'Green')\n",
        "    plt.imshow(test_images[i].reshape(1,28,28)[0], cmap = plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize = (18,18))\n",
        "for i in range(10,19):\n",
        "    if(i == 15):\n",
        "        plt.title('Noised Images', fontsize = 25, color = 'red')\n",
        "    plt.subplot(9,9,i)\n",
        "    plt.imshow(test_noisy_images[i].reshape(1,28,28)[0], cmap = plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize = (18,18))\n",
        "for i in range(10,19):\n",
        "    if(i == 15):\n",
        "        plt.title('Denoised Images', fontsize = 25, color = 'Blue')\n",
        "\n",
        "    plt.subplot(9,9,i)\n",
        "    plt.imshow(model.predict(test_noisy_images[i].reshape(1,28,28,1)).reshape(1,28,28)[0], cmap = plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4VoOLjr7Uw2f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}